# This is Websphere DMGR. It can be only one node.
[dmgr]
dmgr1.internal.example.com

# One or multiple Nodeagents
[was_servers]
connections1.internal.example.com
connections2.internal.example.com

# Location of IHS server(s)
[ihs_servers]
ihs1.internal.example.com
ihs2.internal.example.com

# Server hosting DB2. Automation currently doesn't support any HA on DB2 side.
[db2_servers]
db1.internal.example.com

# Server hosting LDAP. This same server will be used for installing OpenLDAP if that gets attempted.
[ldap_servers]
ldap1.internal.example.com

[ldap_servers:vars]
# Set to false if you want to skip adding fake LDAP users (for example, if you are setting up production environment and you don't need them)
setup_fake_ldap_users=True
# Number of fake users that will be created.
ldap_nr_of_users=2500
# ID of user(s) if creating dummy users for the demo purposes. First one becomes Connections admin, and gets ldap_user_admin_password. All others get
# ldap_user_password as password. Users will be enumerated from ldap_userid1 to ldap_userid2500. Enough for simple performance testing.
ldap_userid="fakeuser"
ldap_user_password="password"
ldap_user_admin_password="password"

# Those variables will be used to set up admin user and password on IHS nodes for IHS itself.
[ihs_servers:vars]
ihs_username=ihsadmin
ihs_password=password

# First node on the list becomes master, gets the folders and get them exported. Other hosts become clients.
[nfs_servers]
dmgr1.internal.example.com
connections1.internal.example.com
connections2.internal.example.com

[all:vars]
# Download location of DB2 and the licence file
db2_download_location=http://installer1.internal.example.com:8001/DB2

# Download location of TDI
tdi_download_location=installer1.internal.example.com:8001/TDI

# Download location of Connections Wizards for DB population
db2_wizards_download_location=installer1.internal.example.com:8001/Connections7

# Download location for IBM Installation manager
iim_repository_url=http://installer1.internal.example.com:8001/was855

# Download location for IBM WebSphere ND & IBM Java
was_repository_url=http://installer1.internal.example.com:8001/was855

# Download location of IBM WAS ND Fixpack 18
was_fixes_repository_url=http://installer1.internal.example.com:8001/was855FP18

# Download location of IBM HTTP Server
ihs_repository_url=http://installer1.internal.example.com:8001/was855

# Download location of IBM HTTP Server fixpacks
ihs_fixes_repository_url=http://installer1.internal.example.com:8001/was855FP18

# Download location of HCL Connections Docs 2.0.1
cnx_docs_download_location=http://installer1.internal.example.com:8001/Docs

# Download location for HCL Connections zip file. Used by Connections installation and TDI to get tdisol archive.
cnx_repository_url=installer1.internal.example.com:8001/Connections7

# Change to Filenames used in Flexnet
was_files[]={"file_name": "CIK2HML.zip", "check_sum": "b1333962ba4b25c8632c7e4c82b472350337e99febac8f70ffbd551ca3905e83" }
was_files[]={"file_name": "CIK2JML.zip", "check_sum": "b73ae070656bed6399a113c2db9fb0abaf5505b0d41c564bf2a58ce0b1e0dcd2" }
was_files[]={"file_name": "CIK2IML.zip", "check_sum": "440b7ed82089d43b1d45c1e908bf0a1951fed98f2542b6d37c8b5e7274c6b1c9" }

ihs_files[]={"file_name": "CIK1VML.zip", "check_sum": "d63c59de4a5548e3d26e71fefb76193d41ac7585bc450c1e504287e0a6f746c9"}
ihs_files[]={"file_name": "CIK1WML.zip", "check_sum": "ac00e7ab43cc528fe7f3ccd69aeb6564a2e738e7bc6e30e71fd2e0d4bd64f39e"}
ihs_files[]={"file_name": "CIK1XML.zip", "check_sum": "94e3d9b70b139ad5fa0578da6857b295c5d2370c1b6ecb544c1e5757406fec90"}

# Folder used for the shared data. If setting up NFS using using automation, it will be created on NFS master and exported, and then mounted by Connections
# installation and used inside response file. 
cnx_shared_area="/nfs/data/shared"
# Folder used for the WAS Message Store share. If setting up NFS using using automation, it will be created on NFS master and exported, and then mounted by Connections
# installation and used inside response file. 
cnx_message_store="/nfs/data/messageStores"

# If enabled, installer will figure out inteligently the the version of Connections you are trying to install. Recommended
# to keep it this way. Otherwise, can be overwritten with a specific version if disabled.
cnx_updates_enabled=True

# This username and password are going to be set as administrative for IBM WebSphere ND and used as such accross whenever
# needed.
was_username=wasadmin
was_password=password
#
# This section is used when setting up OpenLDAP, when setting up TDI and when setting up WebSphere.
ldap_server=ldap1.internal.example.com
ldap_alias=ldap1
ldap_repo=LDAP_PRODUCTION1
ldap_bind_user=cn=Admin,dc=cxn,dc=pnp-hcl,dc=com
ldap_bind_pass=password
ldap_realm=dc=cxn,dc=pnp-hcl,dc=com
ldap_login_properties=uid;mail
#
dmgr_hostname=dmgr1.internal.example.com
was_domainname=.internal.example.com
domain_name=.internal.example.com
cnx_domainname=.internal.example.com
smtp_hostname=localhost
#
ihs_password=password

# The name of at least one IBM HTTP server attached to DMGR prior to installation of Connections. If none web servers with
# this name can be found by Connections installer, some black magic can happen.
cnx_webserver="ihs1"

# Address of Haproxy. This is going to be used as an ingress inside httpd.conf for IBM HTTP server to send requests to the
# Kubernetes cluster and Component Pack.
cnx_component_pack_ingress="web1.internal.example.com"

# This is basically dynamicHost and the value that will be set there.
cnx_application_ingress="web1.example.com"

# uncomment and set this if was_servers and cnx_application_ingress are in different domain
sso_domainname=.internal.example.com;.example.com

# Connections admin user. By default it is this one. Doesn't have to exist in the moment of cluster setup.
connections_admin=fakeuser1

cnx_node_list=['connections1', 'connections2']
cnx_hostname_list=['connections1.internal.example.com', 'connections2.internal.example.com']
ihs_hostname_list=['ihs1.internal.example.com', 'ihs2.internal.example.com']

common_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
communities_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
news_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
widgets_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
profiles_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
search_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}

homepage_app={ 'cluster_name': 'Util', 'nodes':['connections1', 'connections2']}
moderation_app={ 'cluster_name': 'Util', 'nodes':['connections1', 'connections2']}
rte_app={ 'cluster_name': 'Util', 'nodes':['connections1', 'connections2']}

activities_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
blogs_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
dogear_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
files_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
forums_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
metrics_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
mobile_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
wikis_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
ic360_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}

push_app={ 'cluster_name': 'Push', 'nodes':['connections1', 'connections2']}


# Set to true if you want to enable Prometheus JMX exporter and configure WAS to export metrics from one or multiple Connections
# clusters.
enable_prometheus_jmx_exporter=True
# The list of clusters you are exporting, and ports on which you are exporting them. Be careful that ports don't clash with other ports.
connections_jmx_clusters=[{"name":"Apps","port":"8080"}, {"name":"Infra","port":"8081"}, {"name":"Util","port":"8082"}, {"name":"Push","port":"8083"}]

# List of the clusters we are starting by default. In some cases, for example, you don't want to start Push by default or if
# you are not using it.
connections_auto_start_clusters='Apps Push Util Infra'

# This is used by WebSphere, Connections and TDI.
db_username=LCUSER
db_password=password
db_hostname=db1.internal.example.com
db_port=50000
db_jdbc_file=/opt/IBM/db2/V11.1/java
db_type=DB2

# If uncommented (enabled), when running setup-connections-wizards.yml playbook, it would drop your databases and recreate
# them. Use with extreme caution!
#cnx_force_repopulation=True

# If uncommented (enabled), when running setup-connections-wizard.yml playbook, and being already on Connections 6.5.0.1, this would install IC360 database
# and run needed migrations for upgrade to Connections 7. 
#db_enable_upgrades=True

activities_db={ 'server': 'db1.internal.example.com' }
blogs_db={ 'server': 'db1.internal.example.com' }
dogear_db={ 'server': 'db1.internal.example.com' }
communities_db={ 'server': 'db1.internal.example.com' }
files_db={ 'server': 'db1.internal.example.com' }
forums_db={ 'server': 'db1.internal.example.com' }
homepage_db={ 'server': 'db1.internal.example.com' }
metrics_db={ 'server': 'db1.internal.example.com' }
mobile_db={ 'server': 'db1.internal.example.com' }
profiles_db={ 'server': 'db1.internal.example.com' }
push_db={ 'server': 'db1.internal.example.com' }
wikis_db={ 'server': 'db1.internal.example.com' }
icec_db={ 'server': 'db1.internal.example.com' }
ic360_db={ 'server': 'db1.internal.example.com' }

cnx_enable_moderation=true
cnx_enable_invite=true
