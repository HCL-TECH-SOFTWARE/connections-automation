# This is Websphere DMGR. It can be only one node.
[dmgr]
dmgr1.internal.example.com

# One or multiple Nodeagents
[was_servers]
connections1.internal.example.com
connections2.internal.example.com

# Location of IHS server(s)
[ihs_servers]
ihs1.internal.example.com
ihs2.internal.example.com

# Server hosting DB2. Automation currently doesn't support any HA on DB2 side.
[db2_servers]
db1.internal.example.com

# Server hosting LDAP. This same server will be used for installing OpenLDAP if that gets attempted.
[ldap_servers]
ldap1.internal.example.com

[ldap_servers:vars]
# Set to false if you want to skip adding fake LDAP users (for example, if you are setting up production environment and you don't need them)
setup_fake_ldap_users=True
# Number of fake users that will be created.
ldap_nr_of_users=2500
# ID of user(s) if creating dummy users for the demo purposes. First one becomes Connections admin, and gets ldap_user_admin_password. All others get
# ldap_user_password as password. Users will be enumerated from ldap_userid1 to ldap_userid2500. Enough for simple performance testing.
ldap_userid="fakeuser"
ldap_user_password="password"
ldap_user_admin_password="password"

# Those variables will be used to set up admin user and password on IHS nodes for IHS itself.
[ihs_servers:vars]
iim_bin_file="agent.installer.linux.gtk.x86_64_1.9.1003.20200730_2125.zip"
iim_version="1.9.1003.20200730_2125"
ihs_username=ihsadmin
ihs_password=password

# First node on the list becomes master, gets the folders and get them exported. Other hosts become clients.
[nfs_servers]
dmgr1.internal.example.com
connections1.internal.example.com
connections2.internal.example.com

[all:vars]
# Download location of DB2 and the licence file
db2_download_location=http://installer1.internal.example.com:8001/DB2

# Download location of TDI
tdi_download_location=http://installer1.internal.example.com:8001/TDI

# Download location of Connections Wizards for DB population
db2_wizards_download_location=http://installer1.internal.example.com:8001/Connections7

# Download location for IBM Installation manager
iim_repository_url=http://installer1.internal.example.com:8001/was855

# Download location for IBM WebSphere ND & IBM Java
was_repository_url=http://installer1.internal.example.com:8001/was855

# Download location of IBM WAS ND Fixpack 18
was_fixes_repository_url=http://installer1.internal.example.com:8001/was855FP18

# Download location of IBM HTTP Server
ihs_repository_url=http://installer1.internal.example.com:8001/was855

# Download location of IBM HTTP Server fixpacks
ihs_fixes_repository_url=http://installer1.internal.example.com:8001/was855FP18

# Download location of HCL Connections Docs 2.0.1
cnx_docs_download_location=http://installer1.internal.example.com:8001/Docs

# Download location for HCL Connections zip file. Used by Connections installation and TDI to get tdisol archive.
cnx_repository_url=http://installer1.internal.example.com:8001/Connections7

# Uncomment this if you don't want to attempt NFS mounts for your HCL Connections installation. 
# By default, this is set to false.
#skip_nfs_mount_for_connections=true

# Folder used for the shared data. If setting up NFS using using automation, it will be created on NFS master and exported, and then mounted by Connections
# installation and used inside response file. 
cnx_shared_area="/nfs/data/shared"
# Folder used for the WAS Message Store share. If setting up NFS using using automation, it will be created on NFS master and exported, and then mounted by Connections
# installation and used inside response file. 
cnx_message_store="/nfs/data/messageStores"

# If enabled, installer will figure out inteligently the the version of Connections you are trying to install. Recommended
# to keep it this way. Otherwise, can be overwritten with a specific version if disabled.
cnx_updates_enabled=True

# This username and password are going to be set as administrative for IBM WebSphere ND and used as such accross whenever
# needed.
was_username=wasadmin
was_password=password
#
# This section is used when setting up OpenLDAP, when setting up TDI and when setting up WebSphere.
ldap_server=ldap1.internal.example.com
ldap_alias=ldap1
ldap_repo=LDAP_PRODUCTION1
ldap_bind_user=cn=Admin,dc=cxn,dc=pnp-hcl,dc=com
ldap_bind_pass=password
ldap_realm=dc=cxn,dc=pnp-hcl,dc=com
ldap_login_properties=uid;mail
#
dmgr_hostname=dmgr1.internal.example.com
was_domainname=.internal.example.com
domain_name=.internal.example.com
cnx_domainname=.internal.example.com
smtp_hostname=localhost
#
ihs_password=password

# The name of at least one IBM HTTP server attached to DMGR prior to installation of Connections. If none web servers with
# this name can be found by Connections installer, some black magic can happen.
cnx_webserver="ihs1"

# Address of Haproxy. This is going to be used as an ingress inside httpd.conf for IBM HTTP server to send requests to the
# Kubernetes cluster and Component Pack.
cnx_component_pack_ingress="web1.internal.example.com"

# This is basically dynamicHost and the value that will be set there.
cnx_application_ingress="web1.example.com"

# uncomment and set this if was_servers and cnx_application_ingress are in different domain
sso_domainname=.internal.example.com;.example.com

# This is the mandatory variable. This user doesn't have to exist, but is mandatory during HCL Connections response
# file generation. connections_admin will become, as the name suggests, administrator of HCL Connections.
connections_admin=fakeuser1

# This is also mandatory variable for HCL Connections installation. If you are creating fake users, it will be also
# used as their mail sufix. Beside that, it is used by ICXT component configuration to get a HCL Connections administrator
# data during ICXT configuration.
ldap_user_mail_domain="connections.example.com"

cnx_node_list=['connections1', 'connections2']
cnx_hostname_list=['connections1.internal.example.com', 'connections2.internal.example.com']
ihs_hostname_list=['ihs1.internal.example.com', 'ihs2.internal.example.com']

common_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
communities_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
news_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
widgets_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
profiles_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}
search_app={ 'cluster_name': 'Infra', 'nodes':['connections1', 'connections2']}

homepage_app={ 'cluster_name': 'Util', 'nodes':['connections1', 'connections2']}
moderation_app={ 'cluster_name': 'Util', 'nodes':['connections1', 'connections2']}
rte_app={ 'cluster_name': 'Util', 'nodes':['connections1', 'connections2']}

activities_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
blogs_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
dogear_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
files_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
forums_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
metrics_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
mobile_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
wikis_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}
ic360_app={ 'cluster_name': 'Apps', 'nodes':['connections1', 'connections2']}

push_app={ 'cluster_name': 'Push', 'nodes':['connections1', 'connections2']}


# Set to true if you want to enable Prometheus JMX exporter and configure WAS to export metrics from one or multiple Connections
# clusters.
enable_prometheus_jmx_exporter=True
# The list of clusters you are exporting, and ports on which you are exporting them. Be careful that ports don't clash with other ports.
connections_jmx_clusters=[{"name":"Apps","port":"8080"}, {"name":"Infra","port":"8081"}, {"name":"Util","port":"8082"}, {"name":"Push","port":"8083"}]

# List of the clusters we are starting by default. In some cases, for example, you don't want to start Push by default or if
# you are not using it.
connections_auto_start_clusters='Apps Push Util Infra'

# This is used by WebSphere, Connections and TDI.
db_username=LCUSER
db_password=password
db_hostname=db1.internal.example.com
db_port=50000
db_jdbc_file=/opt/IBM/db2/V11.1/java
db_type=DB2

# If uncommented (enabled), when running setup-connections-wizards.yml playbook, it would drop your databases and recreate
# them. Use with extreme caution!
#cnx_force_repopulation=True

# If uncommented (enabled), when running setup-connections-wizard.yml playbook, and being already on Connections 6.5.0.1, this would install IC360 database
# and run needed migrations for upgrade to Connections 7. 
#db_enable_upgrades=True

activities_db={ 'server': 'db1.internal.example.com' }
blogs_db={ 'server': 'db1.internal.example.com' }
dogear_db={ 'server': 'db1.internal.example.com' }
communities_db={ 'server': 'db1.internal.example.com' }
files_db={ 'server': 'db1.internal.example.com' }
forums_db={ 'server': 'db1.internal.example.com' }
homepage_db={ 'server': 'db1.internal.example.com' }
metrics_db={ 'server': 'db1.internal.example.com' }
mobile_db={ 'server': 'db1.internal.example.com' }
profiles_db={ 'server': 'db1.internal.example.com' }
push_db={ 'server': 'db1.internal.example.com' }
wikis_db={ 'server': 'db1.internal.example.com' }
icec_db={ 'server': 'db1.internal.example.com' }
ic360_db={ 'server': 'db1.internal.example.com' }

cnx_enable_moderation=true
cnx_enable_invite=true
